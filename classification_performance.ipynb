{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from ReadBedFiles.ipynb\n",
      "Importing Jupyter notebook from AIListFunc.ipynb\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import nbimporter\n",
    "from collections import Counter\n",
    "import ReadBedFiles\n",
    "from ReadBedFiles import readJsonFile, readFiles2Vector, writeJsonFile, convertMat2document, readJsonFile\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.font_manager as font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(clas_type, label, path_train, path_test, path_universe, path_mat, meta_data, sample_of_interest, path_w2v_model):\n",
    "    path_train = path_train.format(clas_type)\n",
    "    path_test = path_test.format(clas_type)\n",
    "    path_universe = path_universe.format(clas_type)\n",
    "    path_mat = path_mat\n",
    "    meta_data = pd.read_csv(meta_data.format(clas_type))\n",
    "    meta_data = meta_data.loc[meta_data[label].isin(sample_of_interest)][['Experiment_ID', label]]\n",
    "    model = Word2Vec.load(path_w2v_model.format(clas_type))\n",
    "    \n",
    "    return path_train, path_test, path_universe, path_mat, meta_data, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_avg(model, document):\n",
    "    listOfWVs= []\n",
    "    for word in document.split(' '):\n",
    "        if word in model.wv.vocab:\n",
    "            listOfWVs.append(model[word])\n",
    "            \n",
    "    if(len(listOfWVs) == 0):\n",
    "        return np.zeros([100])\n",
    "    return np.mean(listOfWVs, axis=0)\n",
    "\n",
    "def document_embedding_avg(document_Embedding, model):\n",
    "    document_Embedding_avg = {}\n",
    "    for file, doc  in document_Embedding.items():\n",
    "        document_Embedding_avg[file] = embedding_avg(model, doc)\n",
    "    return document_Embedding_avg\n",
    "\n",
    "def create_data4T_SNE(tdMatrix, labels, label, threshld, clm):\n",
    "    tdMatrix =  {k.lower(): v for k, v in tdMatrix.items()}\n",
    "#     print(len((set(labels.Experiment_ID))))\n",
    "    labels.Experiment_ID = list(labels.Experiment_ID.str.lower())\n",
    "#     print(labels.Experiment_ID[0:10])\n",
    "    commonFiles = list(set(tdMatrix.keys())  & set(labels.Experiment_ID)) \n",
    "#     print(len(commonFiles))\n",
    "    y = []\n",
    "    for name in commonFiles:\n",
    "        y.append(labels[labels[clm] == name][label].tolist()[0])\n",
    "    list_of_frequent= y #removeElements(y, threshld)\n",
    "#     print(len(list_of_frequent))\n",
    "    data_X = []\n",
    "    y = []\n",
    "    for name in commonFiles:\n",
    "        y_1 = labels[labels[clm] == name][label].tolist()[0]\n",
    "        if(y_1 in list_of_frequent):\n",
    "            data_X.append(tdMatrix[name])\n",
    "            y.append(y_1)\n",
    "    \n",
    "    return np.array(data_X), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_types = ['antibody', 'cell', 'tissue']\n",
    "labels = ['antibody', 'cell line', 'tissue']\n",
    "sample_of_interest = [['h3k27ac', 'h3k4me3', 'h3k27me3', 'h3k4me1', 'h3k36me3', 'h3k9me3', 'h3k4me2'],\n",
    "                     ['k562', 'mcf7', 'hek293', 'a549', 'hepg2', 'hct116','lovo', 'gm12878', 'lncap','hela'],\n",
    "                     ['liver', 'peripheral blood', 'primary prostate cancer', 'blood', 'breast','bone marrow', 'kidney']\n",
    "                     ]\n",
    "PCA_flg = False\n",
    "label = labels[i]\n",
    "clas_type = clas_types[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['dataset','representation',  'pca', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/esestaff/Documents/GitHub/dataregion-embedding/'\n",
    "path_train = path + 'datasets/{}dataset/train/*'\n",
    "path_test = path + 'datasets/{}dataset/test/*'\n",
    "path_universe = path + 'representations/{}/'\n",
    "path_mat = path + 'datasets/term_doc_mat/'\n",
    "meta_data = path + 'meta_data/meta_data_{}.csv'\n",
    "path_w2v_model = path + 'word2vecmodels/word2vec_{}.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train, path_test, path_universe, path_mat, meta_data, model = initialization(clas_type, label, path_train, path_test, path_universe, path_mat, meta_data, sample_of_interest[i], path_w2v_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/esestaff/Documents/GitHub/region2vec/representations/antibody_universe.txt\n",
      "Reading universe file: Done 2020-11-12 12:24:48.833256\n",
      "2777\n",
      "Reading bed files: Done 2020-11-12 12:27:49.460049\n",
      "Converting to matrix: Done 2020-11-12 12:27:51.814144\n",
      "2777\n",
      "Reading universe file: Done 2020-11-12 12:27:52.070157\n",
      "633\n",
      "Reading bed files: Done 2020-11-12 12:29:18.051001\n",
      "Converting to matrix: Done 2020-11-12 12:29:18.724604\n",
      "633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esestaff/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2777 2777\n",
      "633 633\n",
      "0.9399684044233807\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/F1_classantibody_pcaFalse.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 3020\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/F1_classantibody_pcaFalse.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_univ = '/Users/esestaff/Documents/GitHub/region2vec/representations/antibody_universe.txt'\n",
    "\n",
    "pca = PCA(n_components = 100)\n",
    "\n",
    "print(path_univ)\n",
    "train_files , segmentation_df_train = readFiles2Vector(path_train, path_univ, numberofCores = 4, numOfFiles= 100, PATH = path_train)\n",
    "print(len(train_files))\n",
    "\n",
    "test_files, segmentation_df_test = readFiles2Vector(path_test, path_univ, numberofCores = 4, numOfFiles= 100, PATH = path_test)\n",
    "print(len(test_files))\n",
    "\n",
    "    \n",
    "document_Embedding_train = convertMat2document(train_files, segmentation_df_train)\n",
    "document_Embedding_avg_train = document_embedding_avg(document_Embedding_train, model)\n",
    "\n",
    "\n",
    "document_Embedding_test = convertMat2document(test_files, segmentation_df_test)\n",
    "document_Embedding_avg_test = document_embedding_avg(document_Embedding_test, model)\n",
    " \n",
    "    \n",
    "X_train, y_train = create_data4T_SNE(document_Embedding_avg_train, (meta_data.loc[(meta_data[label] !='none') & (meta_data[label] !='nan') & (meta_data[label].notna())]), label, 0, 'Experiment_ID')\n",
    "X_test, y_test = create_data4T_SNE(document_Embedding_avg_test, (meta_data.loc[(meta_data[label] !='none') & (meta_data[label] !='nan') & (meta_data[label].notna())]), label, 0, 'Experiment_ID')\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))\n",
    "\n",
    "clf = svm.SVC(kernel = 'linear')\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score((y_test), clf.predict(X_test), average = 'micro')\n",
    "print(f1_score((y_test), clf.predict(X_test), average = 'micro'))\n",
    "results = pd.concat([results, pd.DataFrame([[clas_type, 'Region-set2vec', PCA_flg, f1]], columns= ['dataset', 'representation',  'pca', 'f1'])], ignore_index=True)\n",
    "\n",
    "results.to_csv('./results/F1_class{}_pca{}.csv'.format(clas_type, PCA_flg), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
